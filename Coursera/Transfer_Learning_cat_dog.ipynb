{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "390ba6b0-b08a-490f-fdac-4d1feebe8aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "--2020-02-03 03:56:34--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.194.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep  57%[==========>         ]  48.01M   219MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   261MB/s    in 0.3s    \n",
            "\n",
            "2020-02-03 03:56:35 (261 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "bc4bfc45-e948-486c-d2db-58d0ae661666"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "16c9c9ed-ffea-4227-8582-cddc5b7fe7bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-03 03:56:53--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c11::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "\r          /tmp/cats   0%[                    ]       0  --.-KB/s               \r         /tmp/cats_  73%[=============>      ]  48.01M   185MB/s               \r/tmp/cats_and_dogs_ 100%[===================>]  65.43M   211MB/s    in 0.3s    \n",
            "\n",
            "2020-02-03 03:56:54 (211 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "c896f827-9692-4dd1-a777-9a8cd448215c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 20,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 1/20\n",
            "100/100 - 27s - loss: 0.4797 - acc: 0.7695 - val_loss: 0.3341 - val_acc: 0.9070\n",
            "Epoch 2/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3714 - acc: 0.8360 - val_loss: 0.4543 - val_acc: 0.9010\n",
            "Epoch 3/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3317 - acc: 0.8595 - val_loss: 0.2635 - val_acc: 0.9460\n",
            "Epoch 4/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3317 - acc: 0.8695 - val_loss: 0.3573 - val_acc: 0.9380\n",
            "Epoch 5/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3080 - acc: 0.8635 - val_loss: 0.4546 - val_acc: 0.9340\n",
            "Epoch 6/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3165 - acc: 0.8790 - val_loss: 0.2396 - val_acc: 0.9600\n",
            "Epoch 7/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.3251 - acc: 0.8730 - val_loss: 0.5063 - val_acc: 0.9350\n",
            "Epoch 8/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2968 - acc: 0.8725 - val_loss: 0.3032 - val_acc: 0.9580\n",
            "Epoch 9/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2806 - acc: 0.8860 - val_loss: 0.6758 - val_acc: 0.9260\n",
            "Epoch 10/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2751 - acc: 0.8890 - val_loss: 0.3997 - val_acc: 0.9560\n",
            "Epoch 11/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2848 - acc: 0.8875 - val_loss: 0.5534 - val_acc: 0.9450\n",
            "Epoch 12/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2696 - acc: 0.8905 - val_loss: 0.3207 - val_acc: 0.9550\n",
            "Epoch 13/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2681 - acc: 0.8910 - val_loss: 0.4411 - val_acc: 0.9490\n",
            "Epoch 14/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2474 - acc: 0.8950 - val_loss: 0.4038 - val_acc: 0.9520\n",
            "Epoch 15/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2798 - acc: 0.8985 - val_loss: 0.4625 - val_acc: 0.9470\n",
            "Epoch 16/20\n",
            "100/100 - 17s - loss: 0.2673 - acc: 0.8920 - val_loss: 0.3173 - val_acc: 0.9590\n",
            "Epoch 17/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2615 - acc: 0.9020 - val_loss: 0.3814 - val_acc: 0.9590\n",
            "Epoch 18/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2533 - acc: 0.8990 - val_loss: 0.3485 - val_acc: 0.9600\n",
            "Epoch 19/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2370 - acc: 0.9080 - val_loss: 0.4083 - val_acc: 0.9510\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "100/100 - 17s - loss: 0.2403 - acc: 0.8940 - val_loss: 0.6525 - val_acc: 0.9360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "a8cea74b-e22b-44fc-dba6-e85c68c50be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noHEOxwJOFQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "736fbbe2-9d88-47cc-8df1-e838104676b3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}